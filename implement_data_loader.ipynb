{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51633725-6114-4251-9836-86095484a9c9",
   "metadata": {},
   "source": [
    "### IMPLEMENTING A DATA LOADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e639b-ba5a-44c1-92b6-998438c211fb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "For the efficient data loader implementation, we will use PyTorch's built-in Dataset and\n",
    "DataLoader classes.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacee04d-2f36-43a0-87e4-40f02a0ad026",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Tokenize the entire text\n",
    "    \n",
    "Step 2: Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "\n",
    "Step 3: Return the total number of rows in the dataset\n",
    "\n",
    "Step 4: Return a single row from the dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c767c39b-a35d-4dbf-8888-aa35e332974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0388f-124f-4714-88df-847e718ee3ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "The GPTDatasetV1 class in listing 2.5 is based on the PyTorch Dataset class.\n",
    "\n",
    "It defines how individual rows are fetched from the dataset. \n",
    "\n",
    "Each row consists of a number of\n",
    "token IDs (based on a max_length) assigned to an input_chunk tensor. \n",
    "\n",
    "The target_chunk\n",
    "tensor contains the corresponding targets. \n",
    "\n",
    "I recommend reading on to see how the data\n",
    "returned from this dataset looks like when we combine the dataset with a PyTorch\n",
    "DataLoader -- this will bring additional intuition and clarity.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ea4842-e4c1-4cb4-a0b3-63a8c65c4410",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Step 1: Initialize the tokenizer\n",
    "\n",
    "Step 2: Create dataset\n",
    "\n",
    "Step 3: drop_last=True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes\n",
    "during training\n",
    "\n",
    "Step 4: The number of CPU processes to use for preprocessing\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa55001-f432-447f-a2b0-1673446d99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad58bd0a-2719-4f80-856e-5d8b8efeb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b5565-3248-4dcc-8613-a2c11b40df08",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Convert dataloader into a Python iterator to fetch the next entry via Python's built-in next() function\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "418cab3f-6688-4de8-983e-7f660cc21552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n",
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bb9687-c75c-4d6c-a99d-baf2ed65b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad9ab54-04ba-4fc2-bcee-51d0d40b7fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772c65a-0381-4faa-b5e6-16b09b642894",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Note that we increase the stride to 4. This is to utilize the data set fully (we don't skip a\n",
    "single word) but also avoid any overlap between the batches, since more overlap could lead\n",
    "to increased overfitting.\n",
    "    \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
